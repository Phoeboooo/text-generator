{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apple\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 1010402\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "text = open(r'The_Lord_of_the_Rings','r',encoding=\"utf-8_sig\")\n",
    "text = text.read().lower()\n",
    "print('Corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 336781\n",
      "Unique characters: 56\n",
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Length of extracted character sequences\n",
    "maxlen = 60\n",
    "\n",
    "# We sample a new sequence every `step` characters\n",
    "step = 3\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))\n",
    "\n",
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apple\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1247: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               94720     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 56)                7224      \n",
      "=================================================================\n",
      "Total params: 101,944\n",
      "Trainable params: 101,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apple\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1349: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "336781/336781 [==============================] - 533s 2ms/step - loss: 1.7753\n",
      "--- Generating with seed: \"k a deep draught of the air, and felt that a skip and a few \"\n",
      "------ temperature: 1.0\n",
      "k a deep draught of the air, and felt that a skip and a few betten lied, from the ecoing, in the punse-xeep you wanf hey in accounllibut to gimp. an tretfur, and near \n",
      "toom, under a murse. foundains to see of barger, and the feat striver an-somes of the harning heem, shall fresters of into tr all coupshert between of bark brough, the same. a breapule. and egrem be in from boriel. but then thet dilk him. a growsed findless was trading acceaks and e,ply. a b\n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "336781/336781 [==============================] - 510s 2ms/step - loss: 1.5019\n",
      "--- Generating with seed: \" \n",
      "the hobbits lay down on their blankets with their feet tow\"\n",
      "------ temperature: 1.0\n",
      " \n",
      "the hobbits lay down on their blankets with their feet tower. \n",
      " folly year \n",
      "thevica for broken light, that we shall deed. at they had it passor on the shunow son't \n",
      "now betw-set orts last to i nod they i all briven \n",
      "as seuth, and had not unvicourblent. he worms remember they \n",
      "greed north. 'you ca \n",
      "greft a wept shall move and tombithor. tastousing now, had sou the could no seering.' \n",
      "there were wardless asilie very \n",
      "part. the slads it foot sun over truith\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "336781/336781 [==============================] - 515s 2ms/step - loss: 1.4455\n",
      "--- Generating with seed: \" that something horrible was creeping near: there was a son \"\n",
      "------ temperature: 1.0\n",
      " that something horrible was creeping near: there was a son they \n",
      "expect, and it was his \n",
      "little tookting concions to been wome i to that he would on the wores of the hadder that elves might they belare; a darkban. they seemed so sam 'against \n",
      "councing of that dunes. we your trueging of the earths it shiring \n",
      "the \n",
      "home the \n",
      "was \n",
      "wrong you led may turned frost \n",
      "these westo dended to heet as he trued merry doends their hread and \n",
      "minten and for of stirges ne\n",
      "epoch 4\n",
      "Epoch 1/1\n",
      "336781/336781 [==============================] - 497s 1ms/step - loss: 1.4149\n",
      "--- Generating with seed: \"n they could get them). they were hospitable and \n",
      "delighted \"\n",
      "------ temperature: 1.0\n",
      "n they could get them). they were hospitable and \n",
      "delighted that was chap patust, but openish, hrive time their \n",
      "long verse to greut? and wh-ot you, perelate over the company of the same \n",
      "of an imandy forestress of frodo patces \n",
      "among watvers? ' \n",
      "and have looking the oca\n",
      "shefir of or blawn them red guacted. old, something usess of guest, i asking of long ir east: walls the first came like or bilbo's a a \n",
      "flying were reaching he had stridered his eyes! \n",
      "the\n",
      "epoch 5\n",
      "Epoch 1/1\n",
      "336781/336781 [==============================] - 518s 2ms/step - loss: 1.3972\n",
      "--- Generating with seed: \"e got up and drained his own glass silently to the \n",
      "health o\"\n",
      "------ temperature: 1.0\n",
      "e got up and drained his own glass silently to the \n",
      "health of the skift that had looking and wards and were out of a bllgigiff, lurien, frod as hassided usefulding upon that some of \n",
      "upon sirriton of morning, and the leagught star. the unthat isildur seemed through the shire is know. but \n",
      "by far i will have sprang. 'all red looking what to baggins come food the leaguanks \n",
      "elsegent mirrors, throoue ots, began on that above pippin, and keen our \n",
      "he was folk \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 6):\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "    \n",
    "    # this time, we choose only 1.0 temperature to make the training time short\n",
    "    for temperature in [1.0]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
